{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practical 3 NLP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbSVngS0GtSRoNhyrtiyCh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Practical 3**"],"metadata":{"id":"aclHl5QC2i8Y"}},{"cell_type":"markdown","source":["#Aim-: 3A Study of Wordnet Dictionary with methods as synsets, definitions, examples,antonyms"],"metadata":{"id":"y5rk34nkLZfa"}},{"cell_type":"markdown","source":["**WordNet** is the lexical database i.e. dictionary for the English language, specifically designed for natural language processing.\n","\n","Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. Synset instances are the groupings of synonymous words that express the same concept. "],"metadata":{"id":"2KjFDtOD2oOl"}},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hU5dDLaLzBL","executionInfo":{"status":"ok","timestamp":1647961928557,"user_tz":-330,"elapsed":1079,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"d06a1757-88de-495d-92f0-d3f93c6e6586"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__tsHiKSLQ79","executionInfo":{"status":"ok","timestamp":1647961931967,"user_tz":-330,"elapsed":2046,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"7be27c10-dacb-4109-fe6f-3a5b4dbef95f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Synset('computer.n.01'), Synset('calculator.n.01')]\n","a machine for performing calculations automatically\n","Examples: []\n","[Lemma('sell.v.01.sell')]\n"]}],"source":["'''WordNet provides synsets which is the collection of synonym words also called “lemmas”'''\n","import nltk\n","from nltk.corpus import wordnet\n","print(wordnet.synsets(\"computer\"))\n","# definition and example of the word ‘computer’\n","print(wordnet.synset(\"computer.n.01\").definition())\n","#examples\n","print(\"Examples:\", wordnet.synset(\"computer.n.01\").examples())\n","#get Antonyms\n","print(wordnet.lemma('buy.v.01.buy').antonyms())"]},{"cell_type":"markdown","source":["# B.Aim-: Study lemmas, hyponyms, hypernyms."],"metadata":{"id":"ffzQkIqvL8mz"}},{"cell_type":"markdown","source":["WordNet is an English dictionary which is a part of Natural Language Tool Kit (NLTK) for Python. This is an extensive library built to make Natural Language Processing (NLP) easy. Some basic functions will be discussed in this article. To start using WordNet, you have to import it first:\n","\n","# **Synsets and Lemmas**\n","\n","In WordNet, similar words are grouped into a set known as a Synset (short for Synonym-set). Every Synset has a name, a part-of-speech, and a number. The words in a Synset are known as Lemmas.\n","\n","# **Getting Synsets**\n","The function wordnet.synsets('word') returns an array containing all the Synsets related to the word passed to it as the argument.\n","\n","# **Hyponyms**\n","A Hyponym is a specialisation of a Synset. It can be thought of as a child (or derived) class in inheritance. The function hyponyms() returns an array containing all the Synsets which are Hyponyms of the given Synset:\n","\n","# **Hypernyms**\n","A Hypernym is a generalisation of a Synset (i.e. the opposite of a Hyponym). An array containing all Hypernyms of a Synset is returned by hypernyms():"],"metadata":{"id":"Wm15k0Qd3J2Y"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import wordnet\n","print(wordnet.synsets(\"computer\"))\n","print(wordnet.synset(\"computer.n.01\").lemma_names())\n","#all lemmas for each synset.\n","for e in wordnet.synsets(\"computer\"):\n"," print(f'{e} --> {e.lemma_names()}')\n","#print all lemmas for a given synset\n","print(wordnet.synset('computer.n.01').lemmas())\n","#get the synset corresponding to lemma\n","print(wordnet.lemma('computer.n.01.computing_device').synset())\n","#Get the name of the lemma\n","print(wordnet.lemma('computer.n.01.computing_device').name())\n","\n","#Hyponyms give abstract concepts of the word that are much more specific\n","#the list of hyponyms words of the computer\n","syn = wordnet.synset('computer.n.01')\n","print(syn.hyponyms)\n","print([lemma.name() for synset in syn.hyponyms() for lemma in synset.lemmas()])\n","#the semantic similarity in WordNet\n","vehicle = wordnet.synset('vehicle.n.01')\n","car = wordnet.synset('car.n.01')\n","print(car.lowest_common_hypernyms(vehicle))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euWCJlEZLrMH","executionInfo":{"status":"ok","timestamp":1647961978398,"user_tz":-330,"elapsed":16,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"f97ae25f-ef44-4097-d23d-336af5ca9bee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Synset('computer.n.01'), Synset('calculator.n.01')]\n","['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system']\n","Synset('computer.n.01') --> ['computer', 'computing_machine', 'computing_device', 'data_processor', 'electronic_computer', 'information_processing_system']\n","Synset('calculator.n.01') --> ['calculator', 'reckoner', 'figurer', 'estimator', 'computer']\n","[Lemma('computer.n.01.computer'), Lemma('computer.n.01.computing_machine'), Lemma('computer.n.01.computing_device'), Lemma('computer.n.01.data_processor'), Lemma('computer.n.01.electronic_computer'), Lemma('computer.n.01.information_processing_system')]\n","Synset('computer.n.01')\n","computing_device\n","<bound method _WordNetObject.hyponyms of Synset('computer.n.01')>\n","['analog_computer', 'analogue_computer', 'digital_computer', 'home_computer', 'node', 'client', 'guest', 'number_cruncher', 'pari-mutuel_machine', 'totalizer', 'totaliser', 'totalizator', 'totalisator', 'predictor', 'server', 'host', 'Turing_machine', 'web_site', 'website', 'internet_site', 'site']\n","[Synset('vehicle.n.01')]\n"]}]},{"cell_type":"markdown","source":["#C Aim-:Write a program using python to find synonym and antonym of word \"active\"using Wordnet."],"metadata":{"id":"6__GBZLAMIYw"}},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","print( wordnet.synsets(\"active\"))\n","print(wordnet.lemma('active.a.01.active').antonyms())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAvceQX6MDB2","executionInfo":{"status":"ok","timestamp":1647962013598,"user_tz":-330,"elapsed":18,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"71945081-30de-4e26-8ffd-f70e01903221"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Synset('active_agent.n.01'), Synset('active_voice.n.01'), Synset('active.n.03'), Synset('active.a.01'), Synset('active.s.02'), Synset('active.a.03'), Synset('active.s.04'), Synset('active.a.05'), Synset('active.a.06'), Synset('active.a.07'), Synset('active.s.08'), Synset('active.a.09'), Synset('active.a.10'), Synset('active.a.11'), Synset('active.a.12'), Synset('active.a.13'), Synset('active.a.14')]\n","[Lemma('inactive.a.02.inactive')]\n"]}]},{"cell_type":"markdown","source":["#D Aim-:Compare two nouns"],"metadata":{"id":"B-I4XJZ1MPgJ"}},{"cell_type":"markdown","source":["**Nouns** generally refer to people, places, things, or concepts, e.g.: woman, Scotland, book, intelligence. Nouns can appear after determiners and adjectives, and can be the subject or object of the verb"],"metadata":{"id":"KhpaZXtT5AQT"}},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import wordnet\n","syn1 = wordnet.synsets('football')\n","syn2 = wordnet.synsets('soccer')\n","# A word may have multiple synsets, so need to compare each synset of word1with synset of word2:\n","for s1 in syn1:\n","  for s2 in syn2:\n","    print(\"Path similarity of: \")\n","    print(s1, '(', s1.pos(), ')', '[', s1.definition(), ']')\n","    print(s2, '(', s2.pos(), ')', '[', s2.definition(), ']')\n","    print(\" is\", s1.path_similarity(s2))\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFZ4fD0sMLpb","executionInfo":{"status":"ok","timestamp":1647962110389,"user_tz":-330,"elapsed":13,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"e566b6ec-2870-4579-b11f-f67253b5b166"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Path similarity of: \n","Synset('football.n.01') ( n ) [ any of various games played with a ball (round or oval) in which two teams try to kick or carry or propel the ball into each other's goal ]\n","Synset('soccer.n.01') ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents' goal ]\n"," is 0.5\n","\n","Path similarity of: \n","Synset('football.n.02') ( n ) [ the inflated oblong ball used in playing American football ]\n","Synset('soccer.n.01') ( n ) [ a football game in which two teams of 11 players try to kick or head a ball into the opponents' goal ]\n"," is 0.05\n","\n"]}]},{"cell_type":"markdown","source":["#E(i) Aim-:Handling stopword:\n","\n","i) Using nltk Adding or Removing Stop Words in NLTK's Default Stop Word List \n"],"metadata":{"id":"g7ISvDZdMp6S"}},{"cell_type":"markdown","source":["**Stop words** are a set of commonly used words in a language. Examples of stop words in English are “a”, “the”, “is”, “are” and etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so commonly used that they carry very little useful information."],"metadata":{"id":"32UVMz895cId"}},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uo1yyCMDMsZN","executionInfo":{"status":"ok","timestamp":1647962173296,"user_tz":-330,"elapsed":728,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"76ca671d-c24f-47a8-a532-02e67f66944b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Svz2ihV9M5-d","executionInfo":{"status":"ok","timestamp":1647962206560,"user_tz":-330,"elapsed":1059,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"3d3f08d5-abcf-4e26-dfe4-969f1d51d59b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","from nltk.tokenize import word_tokenize\n","text = \"Neha Dawale Roll no 19 likes to play football, however he is not too fond of tennis.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in\n","stopwords.words()]\n","print(tokens_without_sw)\n","#add the word play to the NLTK stop word collection\n","all_stopwords = stopwords.words('english')\n","all_stopwords.append('play')\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","print(tokens_without_sw)\n","#remove ‘not’ from stop word collection\n","all_stopwords.remove('not')\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","print(tokens_without_sw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGn9hXZBMjQd","executionInfo":{"status":"ok","timestamp":1647962289371,"user_tz":-330,"elapsed":714,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"a3e49dbe-a058-46f4-ec00-e762685ee37d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","['Neha', 'Dawale', 'Roll', '19', 'likes', 'play', 'football', ',', 'however', 'fond', 'tennis', '.']\n","['Neha', 'Dawale', 'Roll', '19', 'likes', 'football', ',', 'however', 'fond', 'tennis', '.']\n","['Neha', 'Dawale', 'Roll', '19', 'likes', 'football', ',', 'however', 'not', 'fond', 'tennis', '.']\n"]}]},{"cell_type":"markdown","source":["#E(ii) Aim-: Using Gensim Adding and Removing Stop Words in Default Gensim Stop Words List"],"metadata":{"id":"mlTmblqFNRDP"}},{"cell_type":"markdown","source":[" **Removing Stop Words with Python**\n","\n","With the Python programming language, you have a myriad of options to use in order to remove stop words from strings. You can either use one of the several natural language processing libraries such as NLTK, SpaCy, Gensim, TextBlob, etc., or if you need full control on the stop words that you want to remove, you can write your own custom script.\n","\n","\n","**Adding or Removing Stop Words in NLTK's Default Stop Word List**\n","\n","You can add or remove stop words as per your choice to the existing collection of stop words in NLTK. Before removing or adding stop words in NLTK, let's see the list of all the English stop words supported by NLTK:\n","\n","\n","**Adding Stop Words to Default NLTK Stop Word List**\n","\n","To add a word to NLTK stop words collection, first create an object from the stopwords.words('english') list. Next, use the append() method on the list to add any word to the list.\n","\n","The following script adds the word play to the NLTK stop word collection. Again, we remove all the words from our text variable to see if the word play is removed or not.\n","\n","\n","**Removing Stop Words from Default NLTK Stop Word List**\n","\n","Since stopwords.word('english') is merely a list of items, you can remove items from this list like any other list. The simplest way to do so is via the remove() method. This is helpful for when your application needs a stop word to not be removed. For example, you may need to keep the word not in a sentence to know when a statement is being negated.\n","\n","**Using Python's Gensim Library**\n","\n","The Gensim library is another extremely useful library for removing stop words from a string in Python. All you have to do is to import the remove_stopwords() method from the gensim.parsing.preprocessing module. Next, you need to pass your sentence from which you want to remove stop words, to the remove_stopwords() method which returns text string without the stop words.\n"],"metadata":{"id":"UKVflLyI6UVS"}},{"cell_type":"code","source":["pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dz4a7T3fMzgN","executionInfo":{"status":"ok","timestamp":1647962349537,"user_tz":-330,"elapsed":7130,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"5f104651-08e0-4110-8d3c-353bdc9c1f31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n"]}]},{"cell_type":"code","source":["import gensim\n","from gensim.parsing.preprocessing import remove_stopwords\n","text = \"Neha Dawale Roll No 19 likes to play football, however he is not too fond of tennis.\"\n","filtered_sentence = remove_stopwords(text)\n","print(filtered_sentence)\n","all_stopwords = gensim.parsing.preprocessing.STOPWORDS\n","print(all_stopwords)\n","'''The following script adds likes and play to the list of stop words in Gensim:'''\n","from gensim.parsing.preprocessing import STOPWORDS\n","all_stopwords_gensim = STOPWORDS.union(set(['likes', 'play']))\n","text = \"Neha Dawale Roll No 19  likes to play football, however he is not too fond of tennis.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in\n","all_stopwords_gensim]\n","print(tokens_without_sw) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMkLk3zxNYTO","executionInfo":{"status":"ok","timestamp":1647962435196,"user_tz":-330,"elapsed":585,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"98f5b41c-9d02-43e3-dee5-e23a0269bf54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Neha Dawale Roll No 19 likes play football, fond tennis.\n","frozenset({'thence', 'could', 'unless', 'i', 'some', 'whereas', 'call', 'third', 'therein', 'found', 'part', 'among', 'with', 'around', 'since', 'go', 'between', 'done', 'was', 'herein', 'hundred', 'nine', 'anywhere', 'cannot', 'fifteen', 'name', 'my', 'these', 'now', 'only', 'few', 'latterly', 'yourself', 'ourselves', 'empty', 'none', 'over', 'further', 'toward', 'anyway', 'one', 'although', 'whereupon', 'no', 'using', 'elsewhere', 'km', 'show', 'either', 'down', 'find', 'sixty', 'such', 'together', 'whereby', 'etc', 'onto', 'mostly', 'forty', 'kg', 'this', 'they', 'many', 'whole', 'did', 'full', 'those', 'quite', 'he', 'still', 'up', 'whereafter', 'hence', 'inc', 'two', 'the', 'yours', 'three', 'moreover', 'never', 'because', 'next', 'how', 'from', 'at', 'across', 'nobody', 'into', 'computer', 'might', 'against', 'beforehand', 'noone', 'be', 'somewhere', 'thereby', 'there', 'anything', 'even', 'top', 'whence', 'others', 'former', 'that', 'too', 'detail', 'it', 'de', 'by', 'give', 'where', 'six', 'thin', 'per', 'whatever', 'anyone', 'alone', 'always', 'cant', 'something', 'myself', 'just', 'five', 'him', 'other', 'thereupon', 'becoming', 'thereafter', 'here', 'else', 'as', 'about', 'regarding', 'ours', 'before', 'almost', 'describe', 'amongst', 'become', 'once', 'ever', 'to', 'whose', 'along', 'hasnt', 'less', 'below', 'un', 'has', 'are', 'seems', 'front', 'is', 'doing', 'any', 'our', 'us', 'therefore', 'neither', 'upon', 'namely', 'beside', 'often', 'very', 'didn', 'being', 'make', 'back', 'also', 'more', 'after', 'con', 'their', 'side', 'you', 'via', 'wherein', 'ten', 'take', 'do', 'doesn', 'herself', 'own', 'however', 'every', 'same', 'say', 'while', 'became', 'thick', 'indeed', 'fify', 'would', 'when', 'hereupon', 'yet', 'keep', 'again', 'mill', 'amoungst', 'and', 'see', 'does', 'nor', 'than', 'really', 'seem', 'nothing', 'why', 'least', 'an', 'towards', 'eg', 'am', 'what', 'meanwhile', 'eight', 'four', 'everyone', 'various', 'hers', 'throughout', 'should', 'most', 'both', 'twenty', 'couldnt', 'anyhow', 'himself', 'until', 'someone', 'for', 'thru', 'bill', 'bottom', 'your', 'much', 'hereafter', 'first', 'then', 'during', 'without', 'whether', 'cry', 'everywhere', 'above', 'his', 'amount', 'under', 'formerly', 'had', 'its', 'besides', 'perhaps', 'have', 'of', 'otherwise', 'on', 'whither', 'yourselves', 'afterwards', 'but', 'except', 'were', 'fill', 'serious', 'themselves', 'get', 'within', 'her', 'put', 'due', 'ltd', 'used', 'may', 'everything', 'whoever', 'each', 'all', 'will', 'well', 'enough', 'hereby', 'out', 'twelve', 'several', 'beyond', 'already', 'don', 're', 'seemed', 'sincere', 'we', 'sometimes', 'them', 'move', 'co', 'sometime', 'off', 'interest', 'not', 'whom', 'been', 'thus', 'so', 'she', 'eleven', 'can', 'rather', 'somehow', 'me', 'behind', 'fire', 'ie', 'though', 'becomes', 'please', 'wherever', 'system', 'nevertheless', 'if', 'or', 'itself', 'must', 'a', 'whenever', 'latter', 'made', 'seeming', 'mine', 'last', 'another', 'through', 'nowhere', 'in', 'who', 'which'})\n","['Neha', 'Dawale', 'Roll', 'No', '19', 'football', ',', 'fond', 'tennis', '.']\n"]}]},{"cell_type":"code","source":["'''The following script removes the word \"not\" from the set of stop words in\n","Gensim:'''\n","from gensim.parsing.preprocessing import STOPWORDS\n","all_stopwords_gensim = STOPWORDS\n","sw_list = {\"not\"}\n","all_stopwords_gensim = STOPWORDS.difference(sw_list)\n","text = \"Neha Dawale Roll No 19 likes to play football, however he is not too fond of tennis.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in\n","all_stopwords_gensim]\n","print(tokens_without_sw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CumQe_VJNh8Z","executionInfo":{"status":"ok","timestamp":1647962528686,"user_tz":-330,"elapsed":404,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"42e4a8ad-30cf-4ed4-bbf3-ddc07cf8b40b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Neha', 'Dawale', 'Roll', 'No', '19', 'likes', 'play', 'football', ',', 'not', 'fond', 'tennis', '.']\n"]}]},{"cell_type":"markdown","source":["#E(iii) Aim-:Using Spacy Adding and Removing Stop Words in Default Spacy Stop Words List"],"metadata":{"id":"Db8PZ83ZOP7o"}},{"cell_type":"markdown","source":["Using the **SpaCy Library**\n","The SpaCy library in Python is yet another extremely useful language for natural language processing in Python.\n","\n","**Adding and Removing Stop Words in SpaCy Default Stop Word List**\n","\n","Like the other NLP libraries, you can also add or remove stop words from the default stop word list in Spacy. But before that, we will see a list of all the existing stop words in SpaCy.\n","\n","\n","**Removing Stop Words from Default SpaCy Stop Words List**\n","\n","To remove a word from the set of stop words in SpaCy, you can pass the word to remove to the remove method of the set."],"metadata":{"id":"cRyJvGzT7Wj4"}},{"cell_type":"code","source":["pip install spacy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RDUjVHPKOEFK","executionInfo":{"status":"ok","timestamp":1647962591212,"user_tz":-330,"elapsed":3445,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"8def5015-99e3-474a-ad7d-759affaf2491"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.63.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n"]}]},{"cell_type":"code","source":["import spacy\n","import nltk\n","from nltk.tokenize import word_tokenize\n","sp = spacy.load('en_core_web_sm')\n","#add the word play to the NLTK stop word collection\n","all_stopwords = sp.Defaults.stop_words\n","all_stopwords.add(\"play\")\n","text = \"Neha Dawale Roll No 19 likes to play football, however he is not too fond of tennis.\"\n","text_tokens = word_tokenize(text)\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","print(tokens_without_sw)\n","#remove 'not' from stop word collection all_stopwords.remove('not')\n","tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\n","print(tokens_without_sw) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NdNhyjlAOcRy","executionInfo":{"status":"ok","timestamp":1647962892363,"user_tz":-330,"elapsed":702,"user":{"displayName":"19_neha_dawale","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16793797596584424738"}},"outputId":"9ae9f5b0-bb9f-4eb2-8059-2d70ce569e60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Neha', 'Dawale', 'Roll', 'No', '19', 'likes', 'football', ',', 'not', 'fond', 'tennis', '.']\n","['Neha', 'Dawale', 'Roll', 'No', '19', 'likes', 'football', ',', 'not', 'fond', 'tennis', '.']\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"j0JMy24xPVvZ"},"execution_count":null,"outputs":[]}]}